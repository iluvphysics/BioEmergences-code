{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da9503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tifffile import imread\n",
    "import shutil\n",
    "\n",
    "from vtk_to_tiff_py import save_imagej_tiff, save_imagej_tiff4d\n",
    "\n",
    "#deta = np.genfromtxt('C:/Users/bioAMD/Desktop/Nathan/Tracking/070418a_0.emb', skip_header=1, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5564c34",
   "metadata": {},
   "source": [
    " Fichiers EMB \n",
    " \n",
    "0 : Global Id cell (Id de la cellule traquée)\n",
    "\n",
    "1 : Local Id cell (inutile)\n",
    "\n",
    "2, 3, 4: Coordonnées x, y, z en PIXELS\n",
    "\n",
    "5 : Pas de temps\n",
    "\n",
    "6 : Mother local Id (inutile)\n",
    "\n",
    "7 : Validation -> -1: pas vérifié\n",
    "\n",
    "                   0: vérifié et faux\n",
    "                   \n",
    "                   1: vérifié et vrai\n",
    "                   \n",
    "                   2: vérifié mais non traquée (vrai) \n",
    "                   \n",
    "8: Mother global Id cell (Id de la cellule mère, cellule traquée au temps t - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f436fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positions = np.copy(deta[:,2:5])\n",
    "#print(positions.shape)\n",
    "#cond = np.zeros(tuple([3]) + positions[:,0].shape)\n",
    "#print(cond.shape)\n",
    "#for i in range(len(cond)) :\n",
    "#    if i != 2 :\n",
    "#        cond[i,:] = np.logical_and( positions[:,i] < 256, positions[:,i] > -256)\n",
    "#    else :\n",
    "#        cond[i,:] = positions[:,i] < 104\n",
    "#    \n",
    "#    cond = cond.astype(np.bool_)\n",
    "#    positions[ np.logical_and(cond[0], cond[1], cond[2]) ]\n",
    "#\n",
    "#i = 2\n",
    "#plt.hist(positions[:,i], bins=30)\n",
    "#print(len(positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d0c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produit_scalaire(vec1, vec2) :\n",
    "    assert ( len(vec1.shape) == 1 and len(vec2.shape) == 1), \"Pas des vecteurs.\"\n",
    "    np.sum(vec1*vec2)\n",
    "    \n",
    "def norme(vec) :\n",
    "    return np.sqrt(np.sum(vec**2))\n",
    "\n",
    "def xml_to_dataframe(dir_xml) :\n",
    "    \n",
    "    dict_data = dict()\n",
    "    # on lit les données du fichier XML sous forme d'arbre\n",
    "    tree = ET.parse(dir_xml)\n",
    "    root = tree.getroot() # Experiment\n",
    "    for i,key in enumerate(root.attrib) : # on parcourt les éléments de Experiment\n",
    "        try :\n",
    "            dict_data[key] = int(root.attrib[key])\n",
    "        except :\n",
    "            dict_data[key] = root.attrib[key]\n",
    "            \n",
    "    return pd.DataFrame.from_dict(dict_data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12dd7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, metadata_dir) :\n",
    "    \"\"\" filtre les données ayant mal été traquées par l'algorithme.\n",
    "    data : données du fichier EMB \n",
    "    metadata_dir : Métadonnées du fichier XML \"\"\"\n",
    "    \n",
    "    metadata = xml_to_dataframe(metadata_dir)\n",
    "    data_final = np.copy(data)\n",
    "    \n",
    "    # distance entre frontière de la boîte et le centre (1/2 x longueur)\n",
    "    l = np.zeros(3)\n",
    "    for i, axe in enumerate(['X', 'Y', 'Z']) :\n",
    "        if axe == \"Z\" :\n",
    "            l[i] = int(metadata.loc['db_nbPixel'+axe])\n",
    "        else:\n",
    "            l[i] = int(metadata.loc['db_nbPixel'+axe])//2\n",
    "                \n",
    "    # on ne conserve que les cellules à l'intérieur de la boîte\n",
    "    cond = np.empty( tuple([3]) + data_final[:,0].shape)\n",
    "    for i in range(len(cond)) :\n",
    "        if i != 2 :\n",
    "            cond[i] = np.logical_and(data_final[:,i+2] <= l[i], data_final[:,i+2] > -l[i])\n",
    "        \n",
    "        # l'axe commence à 0\n",
    "        else :\n",
    "            cond[i] = np.logical_and( data_final[:,i+2] <= l[i], data_final[:,i+2] >= 1)\n",
    "        \n",
    "    cond = cond.astype(np.bool_)\n",
    "    data_final = data_final[np.logical_and(np.logical_and(cond[0], cond[1]), cond[2])]\n",
    "    \n",
    "    # on enlève les données classées comme fausses \n",
    "    data_final = data_final[ data_final[:,7] != 0 ]   \n",
    "    \n",
    "    # on ajoute les longueurs aux coordonnées afin d'éviter les valeurs négatives\n",
    "    for i, axe in enumerate(['X', 'Y', 'Z']) :\n",
    "        if axe != 'Z':\n",
    "            L = int(metadata.loc['db_nbPixel'+axe])//2 -1\n",
    "        else :\n",
    "            L = -1\n",
    "        data_final[:,i+2] += L\n",
    "    \n",
    "    return data_final\n",
    "\n",
    "#mdata_dir = \"C:/Users/bioAMD/Desktop/movit941/MovitData/local/070418a/070418a_0.xml\"\n",
    "#data = clean_data(deta, mdata_dir)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3cf1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch(array, vecteur, taille_patch: tuple[int,...], array4d=False, axis=0) :\n",
    "    \"\"\" Crée un patch autour d'un point de coordonnées vecteur (en pixels). \n",
    "    axis : indice de l'axe que l'on garde en totalité \n",
    "    vecteur : array 1D à 3 composantes entières positives \"\"\"\n",
    "    \n",
    "    patch_size = np.uint16(taille_patch)\n",
    "            \n",
    "    # on s'assure qur le patch ne dépasse pas des bords de l'image \n",
    "    axe_skip = 0\n",
    "    for i in range(len(array.shape)) :\n",
    "        if i == axis and array4d :\n",
    "            axe_skip += 1\n",
    "            continue \n",
    "            print(i, np.ma.size(array, axis=i))\n",
    "        assert (vecteur[i-axe_skip] - patch_size[i-axe_skip]//2 >=0 \n",
    "                and vecteur[i-axe_skip] + patch_size[i-axe_skip]//2 < np.ma.size(array, axis=i) ), \"le patch dépasse des bords\"\n",
    "    \n",
    "    assert axis < 4, \"axis trop grand.\"\n",
    "    assert len(vecteur) == len(patch_size) #and len(patch_size) == 3\n",
    "    \n",
    "    if array4d :\n",
    "        if axis == 1 :\n",
    "            newArray = array[vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,:,\n",
    "                            vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                            vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2 ]       \n",
    "        elif axis == 2 :\n",
    "            newArray = array[vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,\n",
    "                            vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                            :, vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2 ] \n",
    "        elif axis == 3 :\n",
    "            newArray = array[vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,\n",
    "                            vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                            vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2, : ]\n",
    "        else :\n",
    "            newArray = array[ :, vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,\n",
    "                            vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                            vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2 ]\n",
    "    else :\n",
    "        newArray = array[vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,\n",
    "                           vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                           vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2 ] \n",
    "    return newArray\n",
    "\n",
    "def positions(emb_data, t, clean=False, metadata_dir=None) :\n",
    "    \"\"\" retourne les positions des cellules au temps t\"\"\"\n",
    "    \n",
    "    assert t <= np.max(emb_data[:,5]), \"t trop grand\"\n",
    "    \n",
    "    data = emb_data\n",
    "    if clean :\n",
    "        data = clean_data(data, metadata_dir)\n",
    "    data = data[np.argwhere(data[:,5] == t)[:,0], 2:5]\n",
    "    return data\n",
    "\n",
    "def cellule_temps(globalId, emb_data, stop= None, clean=False, metadata_dir=None) :\n",
    "    \"\"\" Suit une cellule au cours du temps, à l'envers.\n",
    "    \n",
    "    globalId : Id de la cellule au pas de temps choisi. \n",
    "    clean : Nettoie les données avant de procéder à l'aide du fichier xml (metadata_dir) et de clean_data \n",
    "    stop: nombre de pas revenus en arrière. len(positions) = stop + 1\n",
    "    \n",
    "    Retourne :\n",
    "        positions : tableau (x, y, z) de la cellule à chaque pas de temps (en pixels)\n",
    "        temps : Pas de temps où le tracking a fonctionné \n",
    "        ids_cellule  : GlobalIds pris par la cellule à chaque pas de temps \"\"\"\n",
    "    \n",
    "    assert len(np.argwhere(emb_data[:,0] == globalId)) != 0, \"Cellule {} non trouvée\".format(globalId)\n",
    "    \n",
    "    data = emb_data\n",
    "    if clean :\n",
    "        data = clean_data(data, metadata_dir)\n",
    "    \n",
    "    data_init = data[ data[:,0] == globalId][0]\n",
    "    #print(data_init)\n",
    "    \n",
    "    # initialisation\n",
    "    positions = np.zeros(shape=(int(data[-1,5]), 3))\n",
    "    positions[0], motherId = data_init[2:5], data_init[-1]\n",
    "    \n",
    "    # Pas de temps où le tracking fonctionne\n",
    "    temps = np.zeros(int(data[-1,5]))\n",
    "    temps[0] = 0\n",
    "    \n",
    "    # globalIds de la cellule au cours du temps \n",
    "    ids_cellule = np.zeros(int(data[-1,5]))\n",
    "    ids_cellule[0] = motherId\n",
    "    \n",
    "    for j in range(1,len(positions[:,0])) :       \n",
    "        \n",
    "        # cellule dont le global Id est la mère de la cellule précédente\n",
    "        mother = data[data[:,0] == motherId]\n",
    "        if motherId != 0 and len(mother) > 0 :\n",
    "            mother = mother[0]\n",
    "        else :\n",
    "            mother = []\n",
    "        \n",
    "        # indice de la cellule précédente ayant une mère : tracking réussi\n",
    "        if len(mother) != 0 :\n",
    "            cell_temp = mother[0]\n",
    "        else :\n",
    "            break\n",
    "        \n",
    "        # on extrait la position dela cellule mère et le pas de temps associé\n",
    "        positions[j] = mother[2:5]\n",
    "        temps[j] = mother[5]\n",
    "        ids_cellule[j] = mother[0]\n",
    "            \n",
    "        # id de la cellule mère de la cellule mère\n",
    "        motherId = mother[-1]\n",
    "        \n",
    "        #if motherId == 0 and temps[j] != 0 :\n",
    "        #    #print(\"Cellule {} n'a pas de mère : tracking échoué\".format(str(int(cell_temp))))\n",
    "        #elif motherId == 0 and temps[j] == 0 :\n",
    "            #print('Cellule {} bien traquée.'.format(str(int(cell_temp))))\n",
    "            \n",
    "        # on arrête tout si on dépasse la limite fixée\n",
    "        if stop != None and len(positions[:j]) >= stop :\n",
    "            break\n",
    "    \n",
    "    # on sélectionne uniquement les pas de temps où on peut tracer le linéage de la cellule\n",
    "    trackingSuccess = np.argwhere(positions != np.zeros(3))[::3,0]\n",
    "    \n",
    "    return positions[trackingSuccess], temps[trackingSuccess], ids_cellule[trackingSuccess]\n",
    "\n",
    "def position_cellule(data, globalId: int, t: int, divdata=[]) :\n",
    "    \"\"\" retourne la position de la cellule globalId au pas de temps t \"\"\"\n",
    "    \n",
    "    if len(divdata) == 0 :\n",
    "        mask = np.logical_and( data[:,0] == globalId, data[:,5] == t )\n",
    "        assert len(data[mask]) != 0, \"Cellule {} pas trouvée au pas de temps t = {}.\".format(str(int(globalId)), t)\n",
    "        return data[mask, 2:5]\n",
    "    else :\n",
    "        mask = np.logical_and( divdata[:,1] == globalId, divdata[:,0] == t)\n",
    "        assert len(divdata[mask]) != 0, \"Cellule {} pas trouvée au pas de temps t = {}.\".format(str(int(globalId)), t)\n",
    "        return divdata[mask, 2:5]\n",
    "\n",
    "def cellules_divisions(data, t) :\n",
    "    \"\"\"donne les globalID des cellules qui se divisent au temps t et ses filles. \n",
    "    Une cellule se divise au temps t lorsqu'au pas de temps t+1, elle a deux filles \"\"\"\n",
    "    \n",
    "    cellules_id = data[ data[:,5] == t ]\n",
    "    \n",
    "    # pas de temps d'après \n",
    "    temp_filles = data[ data[:,5] == t+1 ]\n",
    "    \n",
    "    # liste des globalId des mères qui se divisent\n",
    "    divisions = []\n",
    "    \n",
    "    assert len(cellules_id) > 0, \"Aucune cellule à ce pas de temps\"\n",
    "    \n",
    "    for motherId in cellules_id[:,0] :\n",
    "\n",
    "        filles = temp_filles[ temp_filles[:,-1] == motherId, 0 ]\n",
    "        \n",
    "        # si il y a division cellulaire \n",
    "        if len(filles) > 1 :\n",
    "            divisions.append(motherId)\n",
    "            \n",
    "    return divisions\n",
    "\n",
    "def save_divisions(data, save_dir, tstart=0, tstop=None, erase=False) :\n",
    "    \"\"\" sauvegarde dans un fichier les positions des cellules qui se divisent au cours du temps \"\"\"\n",
    "    \n",
    "    position = np.zeros(3)\n",
    "    \n",
    "    # si le fichier de sauvegarde existe déja, on écrit par dessus (sauf si erase est vrai)\n",
    "    if os.path.exists(save_dir) :\n",
    "        if erase :\n",
    "            f = open(save_dir, 'w')\n",
    "        else :\n",
    "            f = open(save_dir, 'a')\n",
    "    else :\n",
    "        f = open(save_dir, 'w')\n",
    "        \n",
    "    f.write('# t globalId x y z \\n')\n",
    "    f.close()\n",
    "    \n",
    "    # tableau des pas de temps\n",
    "    tstop_init = 0\n",
    "    if tstop == None :\n",
    "        tstop_init = np.max(data[:,5])\n",
    "        assert tstart <= np.max(data[:,5]) and tstart >= 0, \"Mauvais intervalle de temps.\"\n",
    "    else :\n",
    "        tstop_init = tstop\n",
    "        assert tstop <= np.max(data[:,5]) and tstop>= tstart, \"Mauvais intervalle de temps.\"\n",
    "    temps = np.arange(tstart, tstop_init+1, step=1)\n",
    "    \n",
    "    for t in temps :\n",
    "        \n",
    "        f = open(save_dir, 'a')\n",
    "        \n",
    "        # on parcourt les cellules qui se divisent et on extrait leur position\n",
    "        divisionsId = cellules_divisions(data, t)\n",
    "        \n",
    "        for i in range(len(divisionsId)) :\n",
    "            \n",
    "            f.write(str(t) + \" \")\n",
    "            f.write(str(int(divisionsId[i])) + \" \")\n",
    "            \n",
    "            position = position_cellule(data, divisionsId[i], t)[0]\n",
    "            \n",
    "            # on écrit les 3 composantes de chaque cellule sur la même ligne\n",
    "            for j in range(len(position)) :\n",
    "                f.write(str(position[j]) + \" \")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.close()\n",
    "                \n",
    "        # nouveau pas de temps: on change de ligne \n",
    "        print(\"t =\",t, \"/\", np.max(temps))\n",
    "        \n",
    "        # on sauvegarde à chaque pas de temps\n",
    "        \n",
    "    return None\n",
    "\n",
    "def filles_division(data, t, deltat, divfile=\"\") :\n",
    "    \"\"\" Calcule les Id des filles de cellules qui se divisent au pas de temps t.\n",
    "    deltat : nombre de pas de temps après la division pour lequel on trouve l'ancêtre\n",
    "    from_file : si on dispose du fichier avec toutes les divisions \n",
    "    divfile : Répertoire où se trouve le fichier des divisions \n",
    "    \n",
    "    Retourne :\n",
    "        dict_liens: dictionnaire où chaque clé correspond au globalId d'une mère (au temps t), et chaque valeur l'ensemble\n",
    "                    des globalId des filles associées (au pas de temps t+deltat)\n",
    "        \"\"\"\n",
    "    print('fonction FILLES_DIVISION')\n",
    "    \n",
    "    # cellules au pas de temps t+deltat\n",
    "    cellules_fin = data[ data[:,5] == t+deltat, 0]\n",
    "    \n",
    "    # cellules s'étant divisées au pas de temps t\n",
    "    if divfile == \"\" :\n",
    "        cellsdiv = cellules_divisions(data, t)\n",
    "    else :\n",
    "        datadiv = np.genfromtxt(divfile, skip_header=1)\n",
    "        cellsdiv = datadiv[datadiv[:,0] == t, 1]\n",
    "    \n",
    "    assert len(cellules_fin) > 0, \"Aucune cellule à ce pas de temps.\"\n",
    "    assert len(cellsdiv) > 0, \"Aucune division à ce pas de temps.\"\n",
    "    \n",
    "    # on répertorie les mères au pas de temps t\n",
    "    set_cellsdiv = set()\n",
    "    dict_liens = {}\n",
    "    for motherId in cellsdiv :\n",
    "        dict_liens[motherId] = set()\n",
    "        set_cellsdiv.add(motherId)\n",
    "    \n",
    "    # on parcourt les cellules du pas de temps t + deltat\n",
    "    compteur = 0\n",
    "    for filleId in cellules_fin :\n",
    "        \n",
    "        positions, temps, ids = cellule_temps(filleId, data, stop=deltat)\n",
    "        if len(positions) <= deltat :\n",
    "            print( \"Tracking échoué : cellule mère de {} perdue ({})\".format(str(int(ids[0])), len(positions)) )\n",
    "            continue \n",
    "        \n",
    "        # si la cellule mère est une des cellules qui s'est divisée au pas de temps t,\n",
    "        # on rajoute la fille sur le dico avec la clé de la mère \n",
    "        if ids[deltat] in set_cellsdiv :\n",
    "            print(\"   BINGO :\", ids[deltat], compteur)\n",
    "            dict_liens[ ids[deltat] ].add(filleId)\n",
    "            \n",
    "        if 100* compteur / (len(cellules_fin)-1) % 5 == 0 :\n",
    "            print(\"filles_division: \",100* compteur / (len(cellules_fin)-1),'%')\n",
    "        compteur += 1\n",
    "                \n",
    "    return dict_liens\n",
    "\n",
    "def calcul_deplacements(data, dict_liens, t, deltat, divfile=\"\") :\n",
    "    \"\"\" Calcule les vecteurs reliant les filles (temps t+deltat) lors d'une division cellulaire au pas de temps t\n",
    "    \n",
    "        dict_liens : dict{motherId: {filles},...}\n",
    "        deltat: nombre de pas où l'on revient en arrière. \n",
    "        divfile: Répertoire du fichier des divisions cellulaires\n",
    "    Retourne :\n",
    "        vect_division: vecteurs reliant les deux filles entre elles pour chaque cellule mère\n",
    "        positions_meres: vecteur position pour chaque cellule mère.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if divfile != \"\" :\n",
    "        datadiv = np.genfromtxt(divfile, skip_header=1)\n",
    "    else : \n",
    "        datadiv= []\n",
    "        \n",
    "    vect_division = np.zeros((len(dict_liens), 3))\n",
    "    positions_meres = np.zeros((len(dict_liens), 3))\n",
    "    \n",
    "    #vecteurs unitaires \n",
    "    e = np.identity(3)\n",
    "    \n",
    "    # on parcourt chaque cellule mère et on regarde la position de ses 2 filles\n",
    "    for i,keyId in enumerate(dict_liens) :\n",
    "        \n",
    "        filles = list(dict_liens[keyId])\n",
    "        if len(filles) <= 1 :\n",
    "            print( 'Deuxième fille de {} perdue. '.format(str(int(keyId))) )\n",
    "            continue\n",
    "        \n",
    "        # vecteur reliant les deux filles (axes XYZ)\n",
    "        position1 = position_cellule(data, filles[0], t+deltat)\n",
    "        position2 = position_cellule(data, filles[1], t+deltat)\n",
    "            \n",
    "        vect_division[i] = position2 - position1\n",
    "        \n",
    "        #position de la mère\n",
    "        positions_meres[i] = position_cellule(data, keyId, t, datadiv)\n",
    "        \n",
    "    return vect_division, positions_meres\n",
    "\n",
    "def arrondi(nbre: float) :\n",
    "    \"\"\" arrondit à l'entier le plus proche \"\"\"\n",
    "    if np.abs(nbre//1 - nbre) <= np.abs((nbre+1)//1 - nbre) :\n",
    "        ent = nbre//1\n",
    "    else :\n",
    "        ent = nbre//1 + 1\n",
    "    return int(ent)\n",
    "\n",
    "def patch_gaussien(vecteur, array_size, patch_size: tuple[int,...], covmat, add=False, img=None) :\n",
    "    \"\"\" Retourne un patch densité de probabilité gaussienne dans un espace à 3 dimensions.\n",
    "        Longueurs en PIXELS\n",
    "        \n",
    "    vecteur : centre du patch, vecteur 3D\n",
    "    covmat : Matrice de covariance de la distribution\n",
    "    add : On ajoute les valeurs sur une matrice 3D déja existante (img)\n",
    "    \"\"\"\n",
    "    \n",
    "    # sécurité\n",
    "    if not add :\n",
    "        array = np.zeros(array_size)\n",
    "    else :\n",
    "        array = np.copy(img)\n",
    "\n",
    "    # fonction gaussienne avec 256 pour maximum \n",
    "    g = lambda x : arrondi( 256*np.exp(-(x - vecteur).T@np.linalg.inv(covmat)@(x - vecteur)) )\n",
    "    \n",
    "    # vecteur déplacement effectué par la transformation array -> patch\n",
    "    deplacement = np.zeros(len(array_size))\n",
    "    for i in range(len(deplacement)) :\n",
    "        deplacement[i] = vecteur[i] - patch_size[i]//2\n",
    "    \n",
    "    # on parcourt les indices de chaque élément du patch, et on calcule la distance avec vecteur (son centre)\n",
    "    \n",
    "    cpte = 0\n",
    "    for i in range(patch_size[0]) :\n",
    "        for j in range(patch_size[1]) :\n",
    "            for k in range(patch_size[2]) :\n",
    "                indx, indy, indz = int(i + deplacement[0]), int(j + deplacement[1]), int(k + deplacement[2])\n",
    "                \n",
    "                if indx < 0 or indx >= len(array[:,0,0]) :\n",
    "                    cpte += 1\n",
    "                    continue\n",
    "                if indy < 0 or indy >= len(array[0,:,0]) :\n",
    "                    cpte += 1\n",
    "                    continue\n",
    "                if indz < 0 or indz >= len(array[0,0,:]) :\n",
    "                    cpte += 1\n",
    "                    continue\n",
    "                x = np.array([indx, indy, indz])\n",
    "                array[indx, indy, indz] += g(x)\n",
    "                \n",
    "                if array[indx, indy, indz] > 255 :\n",
    "                    array[indx, indy,indz] = 255\n",
    "    print(cpte)\n",
    "                \n",
    "    return array\n",
    "\n",
    "def generate_labels(data, array_size, patch_size, t, deltat, sigma, divfile=\"\") :\n",
    "    \"\"\"Génère des images ne comportant que les cellules se divisant au pas de temps t \n",
    "    \n",
    "        deltat : nombre de pas de temps avancés pour identifier les filles\n",
    "        array_size : taille de l'image generée\n",
    "        patch_size : taille du patch sur lequel on ajoute les valeurs de la gaussienne\n",
    "        sigma : variance des directions principales \n",
    "        divfile : Répertoire du fichier des divisions cellulaires. shape=(t, globalId, x,y,z)\n",
    "                    \n",
    "    Retourne :\n",
    "        image : array 3D en sortie \n",
    "    \"\"\"\n",
    "\n",
    "    # dictionaire repertoriant les Id des filles de chaque cellule s'étant divisée\n",
    "    dict_liens = filles_division(data, t, deltat, divfile)\n",
    "    \n",
    "    # vecteurs reliant les filles et positions des mères \n",
    "    vect_deplacement, positions_meres = calcul_deplacements(data, dict_liens, t, deltat, divfile)\n",
    "    \n",
    "    # on modifie les axes des positions mères : axes XYZ -> ZYX \n",
    "    temp = np.copy(positions_meres[:,2])\n",
    "    positions_meres[:,2] = positions_meres[:,0] # XYZ -> XYX\n",
    "    positions_meres[:,0] = temp # XYX -> ZYX\n",
    "    \n",
    "    # et ceux des vecteurs de déplacement\n",
    "    temp = np.copy(vect_deplacement[:,2])\n",
    "    vect_deplacement[:,2] = vect_deplacement[:,0] # XYZ -> XYX\n",
    "    vect_deplacement[:,0] = temp # XYX -> ZYX\n",
    "    \n",
    "    # on enlève les 0 des positions des mères et des vecteurs déplacement\n",
    "    filtre = np.argwhere( positions_meres != np.zeros(len(array_size)))[::len(array_size),0]\n",
    "    vect_deplacement = vect_deplacement[filtre]\n",
    "    positions_meres = positions_meres[filtre]\n",
    "    \n",
    "    # image finale\n",
    "    image = np.zeros(array_size)\n",
    "    \n",
    "    for i in range(len(vect_deplacement)) :  \n",
    "        \n",
    "        # on modifie la matrice de covariance pour prendre en compte l'étalement des cellules qui se divisent  \n",
    "        matcov = np.identity(len(array_size))*sigma #+ np.random.random((len(array_size), len(array_size)))*sigma/4\n",
    "        \n",
    "        vecteur = vect_deplacement[i]\n",
    "        \n",
    "        for j in range(3) :\n",
    "            matcov[j,j] += min(np.abs(vecteur[j]), sigma)\n",
    "        \n",
    "        # on ajoute le patch gaussien generé à l'image finale\n",
    "        image = patch_gaussien(positions_meres[i], array_size, patch_size, matcov, add=True, img = image)\n",
    "        \n",
    "    return image.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e06635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savedir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/070418a_divisions.txt\"\n",
    "# save_divisions(data, savedir, tstart=0, tstop=500, erase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1787437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Créattion des patch gaussiens ##################\n",
    "#base = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/patch_gaussiens\"\n",
    "#div_fichier=\"C:/Users/bioAMD/Desktop/Nathan/Tracking/070418a_divisions.txt\"\n",
    "#\n",
    "#scale = tuple(np.float32([1.34, 1.34, 1.34]))\n",
    "#array_size = (104, 512, 512)\n",
    "#patch_size = (24, 38, 38)\n",
    "#\n",
    "#for t in range(304, 500) :\n",
    "#    image_verdict = generate_labels(data, array_size, patch_size, t, deltat=2, sigma=5, divfile=div_fichier)\n",
    "#    nomFichier = \"070418a_t\"+str(t).zfill(3)+\"_ch09.tif\"\n",
    "#    save_imagej_tiff(base+\"/\"+nomFichier, image_verdict, scale, units=\"um\")\n",
    "#    print(t, \"/\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32d12345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_label(date, images_dir, nb_patches, patch_size, t, maxIter, divfile, array4d=False) :\n",
    "    \"\"\"Crée des patch (tirés aléaoirement) à partir d'une image 3D des labels. \n",
    "    Ils contiennent au moins une division cellulaire.\n",
    "    \n",
    "    date : jeu de donnéees utilisé\n",
    "    images_dir: répertoire des images 3D labels (patch gaussiens)\n",
    "    nb_patches: nombre de patches tirés \n",
    "    maxIter: Nombre maximal de tours de boucles par pas de temps\n",
    "    divfile : répertoire du fichier des divisions cellulaires\n",
    "    \n",
    "    Retourne: \n",
    "        patches_div : array4D shape = (nb_patches, patch_size) des labels\n",
    "        vecteurs_div: coordonnées des centres (aléatoires) des patch contenant des divisions\n",
    "        vecteurs_nodiv : coordonnées de patch ne contenant pas de divisions\n",
    "        indice_t : renvoie l'indice du fichier correspondant au temps t dans os.listdir(images_dir)\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "    indice_t = None\n",
    "    \n",
    "    # on sélectionne l'image correspondant au temps t\n",
    "    files = os.listdir(images_dir)\n",
    "    file_t = \"\"\n",
    "    for i, file in enumerate(files) :\n",
    "        s = 0\n",
    "        while file[len(date)+2+s] != \"_\" :\n",
    "            s += 1\n",
    "        if int(file[len(date)+2:len(date)+2+s]) == t and file[:len(date)] == date :\n",
    "            file_t = file\n",
    "            indice_t = i\n",
    "            \n",
    "    assert file_t != \"\", 'Pas de temps t = {} non trouvé dans {}.'.format(t, images_dir)\n",
    "    \n",
    "    # image 3D à partir du tif\n",
    "    image = imread(images_dir+\"/\"+file_t)\n",
    "        \n",
    "    # positions de toutes les divisions \n",
    "    datadiv = np.genfromtxt(divfile, skip_header=1)\n",
    "    datadiv = datadiv[datadiv[:,0] == t, 2:5]\n",
    "    \n",
    "    # on s'assure que l'image correspond bien au pas de temps t\n",
    "    for i in range(len(datadiv)) :\n",
    "        l,j,k = tuple(datadiv[i].astype(np.uint16))\n",
    "        if image[k,j,l] < 253 :\n",
    "            print(image[k,j,l], (k,j,l))\n",
    "            \n",
    "            # si il y a une erreur, patch_label ne renvoie que des 0.\n",
    "            return 0,0,0,0\n",
    "            #raise Exception(\"L'array 3D ne correspond pas au pas de temps t.\")\n",
    "    \n",
    "    patches_div = np.zeros(tuple([nb_patches]) + patch_size)\n",
    "    vecteurs_div = np.zeros(shape=(nb_patches, 3))\n",
    "    vecteurs_nodiv = []\n",
    "    indices_nodiv = []\n",
    "    \n",
    "    assert maxIter > nb_patches, \"maxIter < nombre de patches. Augmenter maxIter.\"\n",
    "    \n",
    "    # prévention boucle infinie\n",
    "    iter_count = 0\n",
    "    \n",
    "    # nombre de patches sauvegardés\n",
    "    nb_div = 0\n",
    "    \n",
    "    while nb_div < nb_patches and iter_count < maxIter :\n",
    "        \n",
    "        # vecteur 3D aléatoire \n",
    "        low_indices = [patch_size[i]//2 for i in range(len(patch_size)) ]\n",
    "        high_indices = [ np.ma.size(image, axis=i) - patch_size[i]//2 for i in range(len(patch_size)) ]\n",
    "        \n",
    "        # vecteur aléatoire \n",
    "        vecteur = np.random.randint(low=low_indices, high=high_indices, size=3)\n",
    "        \n",
    "        # prévention des dépassements de bords\n",
    "        for i in range(len(patch_size)) :\n",
    "            if vecteur[i] - patch_size[i]//2  < 0 or vecteur[i] + patch_size[i]//2 > np.ma.size(image, axis=i) :\n",
    "                raise Exception(\"Erreur: patch déborde de l'image sur l'axe {}.\".format(i))\n",
    "        \n",
    "        patch = image[vecteur[0]-patch_size[0]//2:vecteur[0]+patch_size[0]//2,\n",
    "                      vecteur[1]-patch_size[1]//2:vecteur[1]+patch_size[1]//2,\n",
    "                      vecteur[2]-patch_size[2]//2:vecteur[2]+patch_size[2]//2 ]\n",
    "    \n",
    "        # si le patch contient une division cellulaire, on le sauvegarde \n",
    "        if np.any(patch > 252) :\n",
    "                patches_div[nb_div] = patch\n",
    "                vecteurs_div[nb_div] = vecteur\n",
    "                nb_div += 1\n",
    "        else :\n",
    "            vecteurs_nodiv.append(vecteur)\n",
    "            \n",
    "        iter_count += 1\n",
    "        \n",
    "    return patches_div, vecteurs_div, np.array(vecteurs_nodiv).astype(np.uint16), indice_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f73f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_timesteps(date:str, files_dir:str, formats=\".tif\") :\n",
    "    \n",
    "    files = os.listdir(files_dir)\n",
    "    # on enlève les fichiers non concernés\n",
    "    for file in files :\n",
    "        if file[-len(formats):] != formats or file[:len(date)] != date :\n",
    "            files.remove(file)\n",
    "            continue\n",
    "\n",
    "    # on répertorie tous les pas de temps\n",
    "    indexes = np.zeros(len(files))\n",
    "    for i, file in enumerate(files) :\n",
    "        s = 0\n",
    "        while file[len(date)+2+s] != \"_\" :\n",
    "            s += 1\n",
    "        indexes[i] = int(file[len(date)+2:len(date)+2+s])\n",
    "    \n",
    "    # on applique la permutation de argsort à la liste de fichiers\n",
    "    mask = np.argsort(indexes)\n",
    "    files = np.array(files)\n",
    "    return files[mask]\n",
    "\n",
    "   \n",
    "    \n",
    "def load_samples(date, input_tifdir, fichiers, indt, demistep=True, troispas=False, nb_forward=1 ) :\n",
    "    \"\"\" Retourne les 2*nb_forward + 1 images 3D correspondant aux pas (t-nb_forward,...,t+nb_forward) sous forme\n",
    "    d'un tableau 4D (3D si troistep est faux)\n",
    "    \n",
    "    fichier : liste des noms de fichiers du répertoire choisi\n",
    "    input_tifdir: répertoire contenant les tif des images de noyaux \n",
    "    indt : indice dans la liste des fichiers input de l'image que l'on charge \n",
    "    \"\"\"\n",
    "    files = sort_timesteps(date, input_tifdir, formats=\".tif\")\n",
    "    \n",
    "    if troispas :\n",
    "        assert indt >= nb_forward and indt + nb_forward < len(files)\n",
    "        \n",
    "    ### on charge les tif correspondant au pas de temps t ou aux pas de temps t-1,t,t+1\n",
    "    # cas où l'image contient deux canaux\n",
    "    shape_data = imread( input_tifdir + \"/\" +files[indt]).shape\n",
    "    if troispas and demistep :\n",
    "        X = np.zeros(tuple([shape_data[0]]) + tuple([2*nb_forward+1]) + shape_data[2:])\n",
    "        \n",
    "        # on choisit le premier canal et on ne lit que les temps paires \n",
    "        for i in range(2*nb_forward+1) :\n",
    "            X[:,i,:,:] = imread(input_tifdir + \"/\" +files[2*(i+indt-nb_forward-1)])[:,0,:,:]\n",
    "            print(input_tifdir + \"/\" +files[2*(i+indt-nb_forward-1)])\n",
    "            \n",
    "    # cas où on veut plusieurs pas mais avec des images à 1 canal\n",
    "    elif troispas :\n",
    "        X = np.zeros( shape_data[0] +tuple([nb_forward]) + shape_data[1:])\n",
    "        \n",
    "        # on prend les pas de temps dans { t-nb_forward,...,t+nb_forward }\n",
    "        for i in range(2*nb_forward+1) :\n",
    "            X[:,i,:,:] = imread( input_tifdir + \"/\" +files[i+indt-nb_forward-1])\n",
    "    else :\n",
    "        X = imread(input_tifdir + \"/\" +files[indt])\n",
    "    \n",
    "    return X\n",
    "\n",
    "def save_samples_patch(date, input_tifdir, gausslabels_dir, output_dir, scale, nb_patches_image, patch_size, divfile,\n",
    "              tstart, tstop, tstep, ch, demistep=False, troispas=False, nb_forward=1):\n",
    "    \n",
    "    \"\"\" Sauvegarde les labels et les images associées dans un répertoire train_dir. \n",
    "    ATTENTION : fichiers sauvegardés -> p = paire (div) et p = impaire (nodiv)\n",
    "    \n",
    "    input_tifdir : répertoire des images tif des cellules \n",
    "    output_dir : répertoire des données d'entrainement. Contient deux dossiers (samples et labels)\n",
    "    gausslabels_dir : répertoire contenant les tif les labels (points gaussiens)\n",
    "    \n",
    "    nb_patches_image : nombre de patches génerés pour chaque image\n",
    "    divfile : fichier des divisions cellulaires. Si il n'y en a pas, mettre divfile = \"\"\n",
    "    demistep : les tifs dans input_tifdir sont des données à deux canaux (bool)\n",
    "    troispas : bool qui indique si on prend plusieurs pas pour les données d'entrainement\n",
    "    nb_forward : nombre de pas pris (nb channels = 2*nb_forward + 1)\n",
    "    \n",
    "    Retourne :\n",
    "        tif des données d'entrainement (samples) rangés dans output_dir/trains_samples\n",
    "        ind_skip : liste des pas de temps passés pour cause d'erreur.\n",
    "        \n",
    "    \"\"\"\n",
    "    files_samples = os.listdir(input_tifdir)\n",
    "    ind_skip = []\n",
    "        \n",
    "    # nb d'itérations maximal pour chaque pas de temps\n",
    "    maxIter = 1000\n",
    "    \n",
    "    if troispas :\n",
    "        assert tstart >= nb_forward\n",
    "    \n",
    "    for t in range(tstart, tstop, tstep) :\n",
    "        \n",
    "        patches_div, vecteurs_div, vecteurs_nodiv, indt = patch_label(date, gausslabels_dir, nb_patches_image, \n",
    "                                                                      patch_size, t, maxIter, divfile, array4d=demistep)\n",
    "        \n",
    "        print(\"t=\", t)\n",
    "        \n",
    "        # si patch_label ne retourne que des 0, on passe le pas de temps t\n",
    "        if isinstance(patches_div, int) : \n",
    "            print(patches_div)\n",
    "            ind_skip.append(t)\n",
    "            continue \n",
    "        assert len(vecteurs_nodiv) >= len(vecteurs_div), \"vecteurs_nodiv: pas assez d'éléments\"\n",
    "        \n",
    "        \n",
    "        ### on charge les tif correspondant au pas de temps t ou aux pas de temps t-1,t,t+1\n",
    "        X = load_samples(date, input_tifdir,files_samples, indt, demistep, troispas, nb_forward)\n",
    "            \n",
    "        # on sauvegarde les patch des images d'entrée\n",
    "        for i in range(len(vecteurs_div)) :\n",
    "                        \n",
    "            # patch contenant ou non une division cellulaire\n",
    "            X_div = patch(X, vecteurs_div[i].astype(np.uint16), patch_size, array4d=demistep, axis=1)\n",
    "            X_div = X_div.astype(np.uint16)\n",
    "            \n",
    "            # nom des fichiers de sauvegarde\n",
    "            sample_div = output_dir + \"/train_samples/\" + date + \"_t\" + str(t).zfill(3) + \"p\" + str(2*i).zfill(2) + \"_ch\" + str(ch).zfill(2) + \".tif\"\n",
    "            \n",
    "            label_div =  output_dir + \"/train_labels/\" + date + \"_t\" + str(t).zfill(3) + \"p\" + str(2*i).zfill(2) + \"_ch\" + str(ch).zfill(2) +\".tif\"\n",
    "            \n",
    "            # sauvegarde des samples avec et sans divisions \n",
    "            save_imagej_tiff4d(sample_div, X_div, scale, units=\"um\")\n",
    "            \n",
    "            # sauvegarde des labels avec et sans divisions\n",
    "            save_imagej_tiff(label_div, patches_div[i].astype(np.uint16), scale, units=\"um\")\n",
    "            \n",
    "        print(t, \"/\", tstop-1)  \n",
    "    return ind_skip\n",
    "\n",
    "def data_rotations(tif_dir, output_dir, axes_flipped, scale, units, labels_dir=\"\", labels_output=\"\") :\n",
    "    \"\"\" Augmente le jeu de données en inversant l'ordre des éléments de chaque array dans tif_dir selon les \n",
    "    axes définis dans axes_flipped.\n",
    "    Fichier de sortie: 070418a_t002_ch06p34c01_ch05.tif \"\"\"\n",
    "    \n",
    "    files = os.listdir(tif_dir)\n",
    "    if labels_dir != \"\" :\n",
    "        labels = os.listdir(labels_dir)\n",
    "        \n",
    "    for i, filename in enumerate(files) :\n",
    "        \n",
    "        # nom du fichier de sortie (on enlève chxx.tif)\n",
    "        ch = filename[-6:-4]\n",
    "        \n",
    "        for axe in axes_flipped :\n",
    "            \n",
    "            # on charge l'array correspondant au tif \n",
    "            X = imread(tif_dir+\"/\"+filename).astype(np.uint16)\n",
    "            \n",
    "            # si l'axe est None, on retourne le fichier tel quel\n",
    "            if axe == None :\n",
    "                save_imagej_tiff4d(output_dir+\"/\"+filename, X, scale, units)\n",
    "                if labels_dir != \"\" :\n",
    "                    Y = imread(labels_dir+\"/\"+labels[i]).astype(np.uint16)\n",
    "                \n",
    "                    # on sépare les cas où il y a plusieurs channels pour les labels\n",
    "                    if len(Y.shape) == 3 :\n",
    "                        save_imagej_tiff(labels_output+\"/\"+labels[i], Y, scale, units)\n",
    "                    else :\n",
    "                        save_imagej_tiff4d(labels_output+\"/\"+labels[i], Y, scale, units)\n",
    "                \n",
    "                continue \n",
    "            \n",
    "            # sinon, on modifie un des axes \n",
    "            X = np.flip(X, axis= axe).astype(np.uint16)\n",
    "            newname = filename[:-9] + 'f'\n",
    "            \n",
    "            # si il y a plusieurs axes à flip, on les écrit à la suite\n",
    "            if isinstance(axe, tuple) :\n",
    "                for k in range(len(axe)) :\n",
    "                    newname += str(axe[k])  \n",
    "            else  :\n",
    "                newname += str(axe).zfill(2)\n",
    "                \n",
    "            newname += '_ch' + ch + \".tif\"\n",
    "            \n",
    "            # si on fournit le dir des labels, on modifie aussi ces données là et on les sauvegarde\n",
    "            if labels_dir != \"\" :\n",
    "                Y = imread(labels_dir+\"/\"+filename)\n",
    "                if len(Y.shape) == 4 :\n",
    "                    Ynew = np.flip(Y, axis= axe)\n",
    "                    save_imagej_tiff4d(labels_output+\"/\"+newname, Ynew, scale, units)\n",
    "                elif len(Y.shape) == 3 :\n",
    "                    # on rajoute une dimension aux labels pour qu'on flip bien les bons axes\n",
    "                    Ynew = np.zeros(tuple([Y.shape[0]]) + tuple([1]) + Y.shape[1:])\n",
    "                    Ynew[:,0,:,:] = np.copy(Y)\n",
    "                    Ynew = np.flip(Ynew, axis= axe)[:,0,:,:].astype(np.uint16)\n",
    "                    save_imagej_tiff(labels_output+\"/\"+newname, Ynew, scale, units)\n",
    "            \n",
    "            # on sauvegarde les données modifiées\n",
    "            save_imagej_tiff4d(output_dir+\"/\"+newname, X, scale, units)\n",
    "            \n",
    "        print(i, \"/\", len(files), )\n",
    "            \n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92006e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Création des patches d'entrainement. p : numéro de patch\n",
    "#inp_tif = \"C:/Users/bioAMD/Desktop/Nathan/Interpolation/dataMix/dataDemistep/demistep_noyaux\"\n",
    "#div_fichier = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/070418a_divisions.txt\"\n",
    "#\n",
    "#output_dir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/train\"\n",
    "#dir_gauss = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/patch_gaussiens\"\n",
    "#\n",
    "#patch_size= (32,64,64)\n",
    "#nb_patches = 20\n",
    "#scaling = tuple(np.float32([1.34,1.34,1.34]))\n",
    "#\n",
    "#indices = save_samples_patch(\"070418a\",inp_tif, dir_gauss, output_dir, scaling, nb_patches, patch_size, div_fichier,\n",
    "#              tstart=2, tstop=101, tstep=1, ch=9, demistep=True, troispas=True, nb_forward=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa42336",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### On augmente les données en faisant des rotations aux patch\n",
    "\n",
    "##outputs\n",
    "#output_dir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/augmentation/train/train_samples\"\n",
    "#labels_output = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/augmentation/train/train_labels\"\n",
    "#\n",
    "## inputs\n",
    "#tif_dir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/train/train_samples\"\n",
    "#labels_dir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/train/train_labels\"\n",
    "#\n",
    "#scale = np.float32([1.367,1.367,1.37])\n",
    "#units='um'\n",
    "#\n",
    "#axes_flipped = [None, 0, 1, 2, (2,0), (3,0), (2,1), (3,1), (3,2,1)]\n",
    "#\n",
    "#data_rotations(tif_dir, output_dir, axes_flipped, scale, units, labels_dir, labels_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ed3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## On met les patch vides dans le stock (inutiles)\n",
    "#dir_train = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/train\"\n",
    "#dir_stock = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/stock\"\n",
    "#\n",
    "#samples = os.listdir(dir_train+\"/train_samples\")\n",
    "#labels = os.listdir(dir_train+\"/train_labels\")\n",
    "#\n",
    "#for i, label in enumerate(labels) :\n",
    "#    # on retire les numéros de pixels impaires (la ou il n'y a rien)\n",
    "#    if int(label[13:15]) % 2 == 1 :\n",
    "#        shutil.move(dir_train+\"/train_labels/\"+label, dir_stock+\"/train_labels/\"+label)\n",
    "#        shutil.move(dir_train+\"/train_samples/\"+samples[i], dir_stock+\"/train_samples/\"+samples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "237e612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(save_imagej_tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9db11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir1 = \"C:/Users/bioAMD/Desktop/Nathan/VTKdata070418/stock_noyaux\"\n",
    "# dir2 = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/saved_predictions/pred_modele_divisions4\"\n",
    "\n",
    "# output = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/saved_predictions/pred_modele_divisions4\"\n",
    "\n",
    "# files = os.listdir(dir2)\n",
    "\n",
    "# scale = np.float32([1.367,1.367,1.37])\n",
    "\n",
    "# for i in range(len(files)-1) :\n",
    "#     if files[i][-4:] != \".tif\" or files[i][9:12] == '006':\n",
    "#         continue\n",
    "        \n",
    "#     x = imread(dir2+\"/\"+files[i])\n",
    "#     y = imread(dir2+\"/\"+files[i+1])\n",
    "#     print(np.sum(x == y), np.size(x), np.size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29ee47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### On crée des données de test\n",
    "#date = \"070418a\"\n",
    "#nb_forward = 2\n",
    "#ch = 9\n",
    "#\n",
    "#tstart = 316\n",
    "#tstop = 500\n",
    "#tstep = 1\n",
    "#\n",
    "#dir_tif = \"C:/Users/bioAMD/Desktop/Nathan/Interpolation/dataMix/dataDemistep/demistep_noyaux\"\n",
    "#test_dir = \"C:/Users/bioAMD/Desktop/Nathan/Tracking/dataDivisions/test\"\n",
    "#\n",
    "#array_size = (104,512,512)\n",
    "#\n",
    "#files = sort_timesteps(date,dir_tif)\n",
    "## on détermine l'indice correspondant à t = tstart\n",
    "#indt = -1\n",
    "#for i, file in enumerate(files) :\n",
    "#    s = 0\n",
    "#    while file[len(date)+2+s] != \"_\" :\n",
    "#        s += 1\n",
    "#    t = int(file[len(date)+2:len(date)+2+s])\n",
    "#    if t == tstart :\n",
    "#        indt = i\n",
    "#        break\n",
    "#assert indt >= 0, \"Pas de temps {} non trouvé.\".format(tstart)\n",
    "#\n",
    "#for t in range(tstart, tstop, tstep) :\n",
    "#    \n",
    "#    # fichier et matrice à sauvegarder\n",
    "#    sample_file = test_dir + \"/test_samples5/\" + date + \"_t\"+str(t).zfill(3)+\"_ch\"+str(ch).zfill(2)+\".tif\"\n",
    "#    image = np.zeros( tuple([array_size[0]]) + tuple([2*nb_forward+1]) + array_size[1:])\n",
    "#    \n",
    "#    print(2*(nb_forward + indt), len(files), \"t=\", t)\n",
    "#    \n",
    "#    # on sauvegarde les 2*nb_forward + 1 pas de temps sur le deuxième axe\n",
    "#    for i in range(2*nb_forward+1) :\n",
    "#        nomFichier = dir_tif + \"/\" +files[2*(i+indt-nb_forward+1)]\n",
    "#        image[:,i,:,:] = imread(nomFichier)[:,0,:,:]\n",
    "#        print(nomFichier)\n",
    "#        \n",
    "#    save_imagej_tiff4d(sample_file, image.astype(np.uint16), scale=(1.367,1.367,1.37), units=\"um\")\n",
    "#    \n",
    "#    # pas de temps suivant\n",
    "#    indt += tstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a078c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
